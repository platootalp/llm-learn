from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"

def sentiment_analysis():
    try:
        # åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æpipeline
        logger.info("æ­£åœ¨åˆå§‹åŒ–æƒ…æ„Ÿåˆ†ææ¨¡å‹...")
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "I love this movie!",
            "This is terrible.",
            "I'm not sure how I feel about this.",
            "Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers."
        ]
        
        logger.info("å¼€å§‹æƒ…æ„Ÿåˆ†æ...")
        results = classifier(test_texts)
        
        # æ‰“å°ç»“æœ
        for text, result in zip(test_texts, results):
            print(f"æ–‡æœ¬: {text}")
            print(f"æƒ…æ„Ÿ: {result['label']}")
            print(f"ç½®ä¿¡åº¦: {result['score']:.4f}")
            print("-" * 50)
            
    except Exception as e:
        logger.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise

def tokenizer_test():
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    print(tokenizer("We are very happy to show you the ğŸ¤— Transformers library."))
    print(tokenizer.tokenize("Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers."))

if __name__ == "__main__":
    # sentiment_analysis()
    tokenizer_test()